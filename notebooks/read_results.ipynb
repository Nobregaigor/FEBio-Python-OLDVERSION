{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1601057063532",
   "display_name": "Python 3.8.5 32-bit ('venv')",
   "metadata": {
    "interpreter": {
     "hash": "4ce963eec525c72576d8dfcde812f8487bbeefd0db94f66638320c10fe71db33"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set paths\n",
    "\n",
    "RESULTS_DIR = \"D:/Igor/Research_USF/University of South Florida/Mao, Wenbin - Igor/Febio-Models/Active-Models/PAQ/Myo_test\"\n",
    "\n",
    "# define headers\n",
    "HEADER_KEY = ['fileName']\n",
    "HEADER_TIM = ['time']\n",
    "HEADER_STR = ['sx','sy','sz','sxy','sxz','syz']\n",
    "HEADER_DIS = ['ux','uy','uz']\n",
    "HEADER_POS = ['x','y','z']\n",
    "HEADER_FAL = ['fail']\n",
    "\n",
    "# define last simulation timestamp\n",
    "LAST_TIMESTAMP = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define functions to find files\n",
    "from os import listdir, makedirs\n",
    "from os.path import isfile, join, isdir\n",
    "\n",
    "def find_files(path_to_folder, condition=None):\n",
    "\tif (condition):\n",
    "\t\tif (condition[0] == \"fileFormat\"):\n",
    "\t\t\t_l = len(condition[1])\n",
    "\t\t\treturn [(join(path_to_folder,f), f,f[:-_l - 1]) for f in listdir(path_to_folder) if isfile(join(path_to_folder, f)) and f[-_l:] == condition[1]]\n",
    "\t\telse:\n",
    "\t\t\traise(ValueError(\"Condition should be a tuple where the first argument is the condition name and the second is its value\"))\n",
    "\telse:\n",
    "\t\treturn [(join(path_to_folder,f), f, f.rsplit(\".\")[0]) for f in listdir(path_to_folder) if isfile(join(path_to_folder, f))]\n",
    "\n",
    "\n",
    "def find_folders(path_to_folder, condition=None):\n",
    "    return [(join(path_to_folder,f), f, f.rsplit(\".\")[0]) for f in listdir(path_to_folder) if isdir(join(path_to_folder, f))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# find files\n",
    "\n",
    "directories = find_folders(RESULTS_DIR)\n",
    "dir_with_files = []\n",
    "for dir in directories:\n",
    "    dir_with_files.append( (dir[-1], find_files(dir[0], (\"fileFormat\", \"txt\"))) )\n",
    "\n",
    "dis_files = {}\n",
    "str_files = {}\n",
    "pos_files = {}\n",
    "for key, files in dir_with_files:\n",
    "    for (fp, ff, fn) in files:\n",
    "        fs = fn.split(\"_\")\n",
    "        if fs[0] == 'displacement':\n",
    "            dis_files[key] = (fp, ff, fn)\n",
    "        elif fs[0] == 'stress':\n",
    "            str_files[key] = (fp, ff, fn)\n",
    "        elif fs[0] == 'position':\n",
    "            pos_files[key] = (fp, ff, fn)\n",
    "files = [str_files, dis_files, pos_files]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[{'myo_hex_8_coarse_PAQ': ('D:/Igor/Research_USF/University of South Florida/Mao, Wenbin - Igor/Febio-Models/Active-Models/PAQ/Myo_test\\\\myo_hex_8_coarse_PAQ\\\\stress.txt',\n   'stress.txt',\n   'stress')},\n {'myo_hex_8_coarse_PAQ': ('D:/Igor/Research_USF/University of South Florida/Mao, Wenbin - Igor/Febio-Models/Active-Models/PAQ/Myo_test\\\\myo_hex_8_coarse_PAQ\\\\displacement_node_out.txt',\n   'displacement_node_out.txt',\n   'displacement_node_out')},\n {'myo_hex_8_coarse_PAQ': ('D:/Igor/Research_USF/University of South Florida/Mao, Wenbin - Igor/Febio-Models/Active-Models/PAQ/Myo_test\\\\myo_hex_8_coarse_PAQ\\\\position_node_out.txt',\n   'position_node_out.txt',\n   'position_node_out')}]"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decode data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set function to read data based on timesteps of the log file\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "def decode_data(file):\n",
    "\tdata = {}\n",
    "\twith open(file, 'r') as datafile:\n",
    "\t\tfor line in datafile:\n",
    "\t\t\tif line.find(\"*Time\") != -1:\n",
    "\t\t\t\ttime = float(line.split(\"=\")[1])\n",
    "\t\t\t\tdata[time] = []\n",
    "\t\t\telif line.find(\"*\") == -1:\n",
    "\t\t\t\tline = re.sub(\"\\n\", '', line)\n",
    "\t\t\t\tline = re.sub(\",\", '', line)\n",
    "\t\t\t\tstr_data = line.split(\" \")\n",
    "\t\t\t\tnode = int(str_data[0])\n",
    "\t\t\t\tnode_data = [float(s) for s in str_data[1:]]\n",
    "\t\t\t\tdata[time].extend(node_data)\n",
    "\tfor key in data:\n",
    "\t\tdata[key] = np.array(data[key])\n",
    "\treturn data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_header():\n",
    "    a = HEADER_KEY + HEADER_TIM + HEADER_FAL + HEADER_POS + HEADER_DIS + HEADER_STR\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# str_data = decode_data(str_files['with_load_myo_hex_coarse_1_epi_60_endo_-60'][0])\n",
    "# str_data.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def create_nodal_df(data, header, only_include_first_and_last=True):\n",
    "    \"\"\" creates a dictionary with keys representing timesteps \"\"\"\n",
    "    dfs = {}\n",
    "    datakeys = data.keys()\n",
    "    if only_include_first_and_last:\n",
    "        datakeys = [datakeys[0], datakeys[-1]]\n",
    "    for key in datakeys:\n",
    "        _subdata = np.array_split(data[key], len(data[key])/len(header))\n",
    "        dfs[key] = pd.DataFrame(_subdata, columns=header)\n",
    "    return dfs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df(data, header, ix_type, only_include_first_and_last=True):\n",
    "    _datastacked = np.empty([1, len(header) + 2])\n",
    "\n",
    "    datakeys = list(data.keys())\n",
    "    datakeys.sort()\n",
    "    if only_include_first_and_last:\n",
    "        if len(datakeys) > 1:\n",
    "            datakeys = [datakeys[0], datakeys[-1]]\n",
    "    for key in datakeys:\n",
    "        _subdata = np.array(np.array_split(data[key], len(data[key])/len(header)))\n",
    "        _timearr = np.ones((len(_subdata), 1)) * key\n",
    "        _nodearr = np.arange(1,len(_subdata)+1,dtype=int).reshape((len(_subdata),1))\n",
    "        _subdata = np.hstack((_timearr,_nodearr, _subdata))\n",
    "        _datastacked = np.concatenate((_datastacked, _subdata))\n",
    "\n",
    "    new_header = np.hstack((['time', ix_type], header))\n",
    "    df = pd.DataFrame(_datastacked, columns=new_header)\n",
    "    df.drop([0], inplace=True)\n",
    "    df = df.reset_index(drop=True)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# str_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# str_dfs = create_df(str_data, HEADER_STR, \"elem\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# str_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Progress: 0 %\nProgress: {} % 100.0\n"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "header = create_header()\n",
    "\n",
    "dfs = []\n",
    "elem_df = pd.DataFrame()\n",
    "node_df = pd.DataFrame()\n",
    "\n",
    "tpm_dir = \"./tmp\"\n",
    "tpm_elem_dir = join(tpm_dir, \"elems\")\n",
    "tpm_node_dir = join(tpm_dir, \"nodes\")\n",
    "\n",
    "for d in [tpm_dir, tpm_elem_dir, tpm_node_dir]:\n",
    "    if not os.path.isdir(d):\n",
    "        os.makedirs(d)\n",
    "\n",
    "max_count = len(str_files)\n",
    "\n",
    "print(\"Progress: 0 %\")\n",
    "for i, key in enumerate(str_files):\n",
    "    df = pd.DataFrame(columns=header)\n",
    "\n",
    "    str_data = decode_data(str_files[key][0])\n",
    "    dis_data = decode_data(dis_files[key][0])\n",
    "    pos_data = decode_data(pos_files[key][0])\n",
    "\n",
    "    str_df = create_df(str_data, HEADER_STR, \"elem\")\n",
    "    dis_df = create_df(dis_data, HEADER_DIS, \"node\")\n",
    "    pos_df = create_df(pos_data, HEADER_POS, \"node\")\n",
    "\n",
    "    \n",
    "\n",
    "    l_elem_df = str_df\n",
    "    # l_node_df = pd.concat((pos_df, dis_df), axis=1)\n",
    "    l_node_df = pos_df.merge(dis_df, how='outer')\n",
    "\n",
    "    l_elem_df[\"fileName\"] = key\n",
    "    l_node_df[\"fileName\"] = key\n",
    "\n",
    "    l_elem_df.to_pickle(join(tpm_elem_dir, \"elem_df_%s.pickle\" % key))\n",
    "    l_node_df.to_pickle(join(tpm_node_dir, \"node_df_%s.pickle\" % key))\n",
    "\n",
    "    print(\"Progress: {} %\", 100 * ((i+1)/max_count))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# l_node_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "compiled pickle:  1.0\ncompiled pickle:  1.0\n"
    }
   ],
   "source": [
    "def compile_data(files):\n",
    "\tframes = []\n",
    "\ttotal_files = len(files)\n",
    "\tfor i, (fp, _, _) in enumerate(files):\n",
    "\t\tndf = pd.read_pickle(fp)\n",
    "\t\tframes.append(ndf)\n",
    "\t\tprint(\"compiled pickle: \", (i + 1) /total_files)\n",
    "\t\tdf = pd.concat(frames, ignore_index=True)\n",
    "\treturn df\n",
    "\n",
    "elem_pickle_files = find_files(tpm_elem_dir, (\"fileFormat\",\"pickle\"))\n",
    "node_pickle_files = find_files(tpm_node_dir, (\"fileFormat\",\"pickle\"))\n",
    "\n",
    "elem_df = compile_data(elem_pickle_files)\n",
    "node_df = compile_data(node_pickle_files)\n",
    "\n",
    "out_dir = \"./compiled_data\"\n",
    "if not os.path.isdir(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "\n",
    "elem_df.to_pickle(join(out_dir, \"elems_compiled\" + \".pickle\"))\n",
    "node_df.to_pickle(join(out_dir, \"nodes_compiled\" + \".pickle\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "        time     node             x             y        z        ux  \\\n0      0.004      1.0 -9.344340e-03 -1.942380e-02 -65.1808 -0.009344   \n1      0.004      2.0  2.143130e-15 -5.249160e-31 -75.5475  0.000000   \n2      0.004      3.0  3.414030e+01 -1.449470e+00  20.0000  0.407643   \n3      0.004      4.0  2.444760e+01  1.123150e+00  20.0000  0.660492   \n4      0.004      5.0 -2.344110e-03 -9.428740e-03 -66.5087 -0.002344   \n...      ...      ...           ...           ...      ...       ...   \n45013  0.200  22505.0  2.733940e+01 -2.168970e+01  17.5604  0.845670   \n45014  0.200  22506.0  2.984460e+01 -1.809090e+01  17.5538  1.147230   \n45015  0.200  22507.0  3.187140e+01 -1.420330e+01  17.5553  1.423050   \n45016  0.200  22508.0  3.339640e+01 -1.009450e+01  17.5532  1.677140   \n45017  0.200  22509.0  3.439860e+01 -5.832850e+00  17.5531  1.908750   \n\n             uy        uz              fileName  \n0     -0.019424 -0.180786  myo_hex_8_coarse_PAQ  \n1      0.000000 -0.547491  myo_hex_8_coarse_PAQ  \n2     -1.449470  0.000000  myo_hex_8_coarse_PAQ  \n3      1.123150  0.000000  myo_hex_8_coarse_PAQ  \n4     -0.009429 -0.258713  myo_hex_8_coarse_PAQ  \n...         ...       ...                   ...  \n45013 -2.440830 -0.306306  myo_hex_8_coarse_PAQ  \n45014 -2.314400 -0.312968  myo_hex_8_coarse_PAQ  \n45015 -2.147970 -0.311459  myo_hex_8_coarse_PAQ  \n45016 -1.950340 -0.313567  myo_hex_8_coarse_PAQ  \n45017 -1.728430 -0.313573  myo_hex_8_coarse_PAQ  \n\n[45018 rows x 9 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>time</th>\n      <th>node</th>\n      <th>x</th>\n      <th>y</th>\n      <th>z</th>\n      <th>ux</th>\n      <th>uy</th>\n      <th>uz</th>\n      <th>fileName</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.004</td>\n      <td>1.0</td>\n      <td>-9.344340e-03</td>\n      <td>-1.942380e-02</td>\n      <td>-65.1808</td>\n      <td>-0.009344</td>\n      <td>-0.019424</td>\n      <td>-0.180786</td>\n      <td>myo_hex_8_coarse_PAQ</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.004</td>\n      <td>2.0</td>\n      <td>2.143130e-15</td>\n      <td>-5.249160e-31</td>\n      <td>-75.5475</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>-0.547491</td>\n      <td>myo_hex_8_coarse_PAQ</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.004</td>\n      <td>3.0</td>\n      <td>3.414030e+01</td>\n      <td>-1.449470e+00</td>\n      <td>20.0000</td>\n      <td>0.407643</td>\n      <td>-1.449470</td>\n      <td>0.000000</td>\n      <td>myo_hex_8_coarse_PAQ</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.004</td>\n      <td>4.0</td>\n      <td>2.444760e+01</td>\n      <td>1.123150e+00</td>\n      <td>20.0000</td>\n      <td>0.660492</td>\n      <td>1.123150</td>\n      <td>0.000000</td>\n      <td>myo_hex_8_coarse_PAQ</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.004</td>\n      <td>5.0</td>\n      <td>-2.344110e-03</td>\n      <td>-9.428740e-03</td>\n      <td>-66.5087</td>\n      <td>-0.002344</td>\n      <td>-0.009429</td>\n      <td>-0.258713</td>\n      <td>myo_hex_8_coarse_PAQ</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>45013</th>\n      <td>0.200</td>\n      <td>22505.0</td>\n      <td>2.733940e+01</td>\n      <td>-2.168970e+01</td>\n      <td>17.5604</td>\n      <td>0.845670</td>\n      <td>-2.440830</td>\n      <td>-0.306306</td>\n      <td>myo_hex_8_coarse_PAQ</td>\n    </tr>\n    <tr>\n      <th>45014</th>\n      <td>0.200</td>\n      <td>22506.0</td>\n      <td>2.984460e+01</td>\n      <td>-1.809090e+01</td>\n      <td>17.5538</td>\n      <td>1.147230</td>\n      <td>-2.314400</td>\n      <td>-0.312968</td>\n      <td>myo_hex_8_coarse_PAQ</td>\n    </tr>\n    <tr>\n      <th>45015</th>\n      <td>0.200</td>\n      <td>22507.0</td>\n      <td>3.187140e+01</td>\n      <td>-1.420330e+01</td>\n      <td>17.5553</td>\n      <td>1.423050</td>\n      <td>-2.147970</td>\n      <td>-0.311459</td>\n      <td>myo_hex_8_coarse_PAQ</td>\n    </tr>\n    <tr>\n      <th>45016</th>\n      <td>0.200</td>\n      <td>22508.0</td>\n      <td>3.339640e+01</td>\n      <td>-1.009450e+01</td>\n      <td>17.5532</td>\n      <td>1.677140</td>\n      <td>-1.950340</td>\n      <td>-0.313567</td>\n      <td>myo_hex_8_coarse_PAQ</td>\n    </tr>\n    <tr>\n      <th>45017</th>\n      <td>0.200</td>\n      <td>22509.0</td>\n      <td>3.439860e+01</td>\n      <td>-5.832850e+00</td>\n      <td>17.5531</td>\n      <td>1.908750</td>\n      <td>-1.728430</td>\n      <td>-0.313573</td>\n      <td>myo_hex_8_coarse_PAQ</td>\n    </tr>\n  </tbody>\n</table>\n<p>45018 rows Ã— 9 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "node_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}